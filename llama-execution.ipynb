{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18db320e-8148-480b-abcd-e4daa7a7299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c9d7d69-65e9-4ff2-9675-dae0dc6389ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ad6d379-12fd-4bf1-b115-2b24897f4f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 27 05:32:58 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.05              Driver Version: 535.86.05    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A5000               On  | 00000000:01:00.0 Off |                  Off |\n",
      "| 94%   32C    P8              26W / 190W |  15322MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be245041-fd49-4cb4-8f79-51a3658219cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded in 6.95 seconds\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import fire\n",
    "\n",
    "from llama import Llama\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"RANK\"]=\"0\"\n",
    "os.environ[\"WORLD_SIZE\"]=\"1\"\n",
    "os.environ[\"MASTER_ADDR\"]=\"127.0.0.1\"\n",
    "os.environ[\"MASTER_PORT\"]=\"29500\"\n",
    "\n",
    "os.environ[\"LOCAL_WORLD_SIZE\"]=\"1\"\n",
    "os.environ[\"WORLD_SIZE\"]=\"1\"\n",
    "os.environ[\"GROUP_WORLD_SIZE\"]=\"1\"\n",
    "os.environ[\"ROLE_WORLD_SIZE\"]=\"1\"\n",
    "\n",
    "\n",
    "\n",
    "generator = Llama.build(\n",
    "    ckpt_dir=\"/git/codellama/CodeLlama-7b-Instruct/\",\n",
    "    tokenizer_path=\"/git/codellama/CodeLlama-7b-Instruct/tokenizer.model\",\n",
    "    max_seq_len=512,\n",
    "    max_batch_size=8,\n",
    "    model_parallel_size=1\n",
    ")\n",
    "\n",
    "instructions = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"In Bash, how do I list all text files in the current directory (excluding subdirectories) that have been modified in the last month?\",\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the difference between inorder and preorder traversal? Give an example in Python.\",\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Provide answers in JavaScript\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a function that computes the set of sums of all contiguous sublists of a given list.\",\n",
    "        }\n",
    "    ],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0dc8304-26b3-4d8e-b9cd-c0fba26d11a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is an example of a unit test for the `Fibonacci` class:\n",
      "```\n",
      "import org.junit.Test;\n",
      "import static org.junit.Assert.*;\n",
      "\n",
      "public class FibonacciTest {\n",
      "\n",
      "    @Test\n",
      "    public void testFibonacci() {\n",
      "        int n = 10;\n",
      "        int[] expected = {0, 1, 1, 2, 3, 5, 8, 13, 21, 34};\n",
      "        int[] actual = Fibonacci.fibonacci(n);\n",
      "        assertArrayEquals(expected, actual);\n",
      "    }\n",
      "}\n",
      "```\n",
      "This test case uses the `assertArrayEquals` method from JUnit to compare the expected and actual results of the `fibonacci` method. The `fibonacci` method is called with the input `n = 10`, and the expected result is an array of the first 10 Fibonacci numbers. The actual result is calculated using the `fibonacci` method, and the test fails if the two arrays are not equal.\n",
      "\n",
      "You can run this test case using a JUnit test runner, such as the `JUnitCore` class in JUnit 4. The test runner will execute the test case and print the results, including any failures.\n",
      "\n",
      "Note that this is just one example of a unit test for the `Fibonacci` class.\n"
     ]
    }
   ],
   "source": [
    "results = generator.chat_completion(\n",
    "    [[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "             Write a unit test for this program\n",
    "\n",
    "                public class Fibonacci {\n",
    "                  public static void main(String[] args) {\n",
    "                    int n = 10; // number of terms to print\n",
    "                    int a = 0, b = 1; // first two terms of the sequence\n",
    "                    System.out.print(a + \" \" + b); // print the first two terms\n",
    "                    for (int i = 2; i < n; i++) {\n",
    "                      int c = a + b; // calculate the next term\n",
    "                      System.out.print(\" \" + c); // print the next term\n",
    "                      a = b; // shift the previous term to a\n",
    "                      b = c; // shift the current term to b\n",
    "                    }\n",
    "                    System.out.println();\n",
    "                  }\n",
    "                }\n",
    "\n",
    "            \"\"\",\n",
    "        }\n",
    "    ]],  # type: ignore\n",
    "    max_gen_len=None,\n",
    "    temperature=0.2,\n",
    "    top_p=0.95,\n",
    ")\n",
    "print(results[0]['generation']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e75324-6948-4e5d-ae6d-6f55f1c1d09a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
